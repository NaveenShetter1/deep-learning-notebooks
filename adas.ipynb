{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBrbmc3Th85E9tsksZQBUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaveenShetter1/deep-learning-notebooks/blob/main/adas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Detection with YOLO"
      ],
      "metadata": {
        "id": "ixIvAQauXFNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ultralytics/yolov5/master/data/coco.names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEYFg90ZYAfE",
        "outputId": "80425e21-dae1-43ea-de16-b1dd737b0a0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-12 12:41:07--  https://raw.githubusercontent.com/ultralytics/yolov5/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-11-12 12:41:07 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/ultralytics/yolov5/master/data/coco.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ob3zxFcZRI9",
        "outputId": "77220d7d-8003-474a-debf-613cbebf9137"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-12 12:42:00--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  12.4MB/s    in 43s     \n",
            "\n",
            "2024-11-12 12:43:16 (5.54 MB/s) - ‘yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n",
            "--2024-11-12 12:43:16--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg.1’\n",
            "\n",
            "yolov3.cfg.1        100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-12 12:43:16 (50.5 MB/s) - ‘yolov3.cfg.1’ saved [8342/8342]\n",
            "\n",
            "--2024-11-12 12:43:16--  https://raw.githubusercontent.com/ultralytics/yolov5/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-11-12 12:43:16 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eJLMFc48U2sh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Upload yolov3.weights, yolov3.cfg, and coco.names files before running\n",
        "\n",
        "# Load YOLO model (Pre-trained weights and config)\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = net.getUnconnectedOutLayersNames()\n",
        "\n",
        "\n",
        "# Load class labels for YOLO (COCO dataset)\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Initialize the video stream (use a camera or video file)\n",
        "cap = cv2.VideoCapture(0)  # Replace '0' with the path to your video file\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Prepare the image for YOLO (resize and normalize)\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Post-process YOLO outputs\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    height, width, channels = frame.shape\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:  # Threshold for object detection\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply non-maxima suppression to avoid multiple boxes around the same object\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # Draw detected objects\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            color = (0, 255, 0)  # Green color for bounding box\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "    # Show the frame\n",
        "    cv2.imshow(\"ADAS Object Detection\", frame)\n",
        "\n",
        "    # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lane Detection (Hough Transform)"
      ],
      "metadata": {
        "id": "bQpT5igsXYGm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_lane(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform Canny edge detection\n",
        "    edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Define a region of interest (ROI) where lanes are expected\n",
        "    height, width = edges.shape\n",
        "    roi_vertices = [(0, height), (width // 2, int(height * 0.6)), (width, height)]\n",
        "    mask = np.zeros_like(edges)\n",
        "    cv2.fillPoly(mask, np.array([roi_vertices], dtype=np.int32), 255)\n",
        "    masked_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "    # Detect lines using Hough Transform\n",
        "    lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, threshold=100, minLineLength=50, maxLineGap=50)\n",
        "\n",
        "    # Draw the detected lanes on the original image\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Initialize the video stream (use a camera or video file)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect and draw lane markings\n",
        "    lane_frame = detect_lane(frame)\n",
        "\n",
        "    # Show the frame with lane markings\n",
        "    cv2.imshow(\"ADAS Lane Detection\", lane_frame)\n",
        "\n",
        "    # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Y5fNdDuHXetm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Integration for Real-Time ADAS"
      ],
      "metadata": {
        "id": "Djspvm8bXjhO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Object detection and lane detection functions from above\n",
        "# Use the object detection function and lane detection function\n",
        "\n",
        "def process_frame(frame):\n",
        "    # Step 1: Detect lanes\n",
        "    lane_frame = detect_lane(frame)\n",
        "\n",
        "    # Step 2: Detect objects (e.g., vehicles, pedestrians)\n",
        "    # Object detection code from the YOLO model goes here\n",
        "\n",
        "    # Combine results\n",
        "    combined_frame = lane_frame  # Add object detection on top of lane detection\n",
        "    return combined_frame\n",
        "\n",
        "# Initialize the video stream (use a camera or video file)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process frame with both lane and object detection\n",
        "    output_frame = process_frame(frame)\n",
        "\n",
        "    # Show the output frame\n",
        "    cv2.imshow(\"ADAS Real-Time System\", output_frame)\n",
        "\n",
        "    # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "yr5B9O_EXnh_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoHk1XxzZwjO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}